---
phase: 07-image-array-migration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/migrations/20260203000000-merge-image-arrays.js
  - backend/scripts/audit-image-data.js
autonomous: true

must_haves:
  truths:
    - "Running DRY_RUN=true shows preview of migration changes without modifying database"
    - "Audit script identifies all edge cases (missing mainImage, missing smallImages, both, neither)"
    - "Migration script transforms mainImage + smallImages into unified images array"
    - "First element in images array preserves mainImage responsive structure"
    - "Rollback (down) method reverses migration by splitting images array back"
  artifacts:
    - path: "backend/migrations/20260203000000-merge-image-arrays.js"
      provides: "migrate-mongo migration with up/down methods and dry-run support"
      exports: ["up", "down"]
    - path: "backend/scripts/audit-image-data.js"
      provides: "Standalone audit script for pre-migration data quality check"
  key_links:
    - from: "backend/migrations/20260203000000-merge-image-arrays.js"
      to: "products collection"
      via: "db.collection('products')"
      pattern: "db\\.collection\\(['\"]products['\"]\\)"
---

<objective>
Create migration infrastructure with dry-run capability and pre-migration audit tooling.

Purpose: Establish safe migration foundation with full visibility into data transformation before committing changes. STATE.md flags this as high-risk (Pitfall #4), requiring conservative approach with pre-migration audit and rollback capability.

Output: Migration script with dry-run mode, standalone audit script, and documented rollback procedure.
</objective>

<execution_context>
@C:\Users\pagis\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\pagis\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-image-array-migration/07-RESEARCH.md
@.planning/phases/07-image-array-migration/07-CONTEXT.md
@backend/models/Product.js
@backend/migrations/20260201194100-add-product-display-order.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create standalone audit script</name>
  <files>backend/scripts/audit-image-data.js</files>
  <action>
Create a standalone Node.js script that connects to MongoDB and audits image data quality.

The script MUST:
1. Connect to MongoDB using same config as migrate-mongo (read migrate-mongo-config.js)
2. Count and report:
   - Total products
   - Products with mainImage (object with desktop/mobile)
   - Products with smallImages (array)
   - Products with both mainImage AND smallImages
   - Products with neither (no images)
   - Products with legacy `image` string field
   - Products with `smallImagesLocal` array
3. Detect data corruption:
   - mainImage that is a string instead of object
   - smallImages that is not an array
   - Empty/null values in image URLs
4. Sample 3 products and display their image structure (before/after preview)
5. Exit with code 0 if safe to migrate, code 1 if corruption detected

Use dotenv for environment variables. Make it runnable via `node backend/scripts/audit-image-data.js`.

Reference the auditImageData function pattern from 07-RESEARCH.md Code Examples section.
  </action>
  <verify>
Run `node backend/scripts/audit-image-data.js` and confirm:
- Script connects to database successfully
- Outputs counts for all image field variations
- Shows sample product image structures
- Exits cleanly with appropriate code
  </verify>
  <done>
Audit script runs successfully and provides actionable data quality report with edge case counts and sample previews.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create migration with dry-run support</name>
  <files>backend/migrations/20260203000000-merge-image-arrays.js</files>
  <action>
Create migrate-mongo migration file following established pattern from 20260201194100-add-product-display-order.js.

The migration MUST implement:

**up() method:**
1. Check DRY_RUN environment variable at start
2. Run pre-migration validation (count corruption, fail if found)
3. Use cursor-based iteration (not .toArray()) for memory efficiency
4. Transform each product:
   - If mainImage exists: images[0] = mainImage object (preserve all 6 fields)
   - If smallImages exists: images[1..n] = smallImages array elements
   - If only smallImages and no mainImage: first smallImages becomes images[0]
   - Handle legacy string formats by converting to object structure
5. Use bulkWrite with batching (1000 docs per batch) for performance
6. In DRY_RUN mode: Show transformation preview for first 3 products, skip actual writes
7. Log progress and final counts
8. DO NOT remove old fields (mainImage, smallImages) - keep for backwards compatibility

**down() method:**
1. Find all products with images array
2. Split images[0] back to mainImage
3. Split images[1..n] back to smallImages
4. Remove images field
5. Log rollback progress

**mergeImageArrays helper function:**
- Accept mainImage (object or null) and smallImages (array or null)
- Return unified images array with consistent object structure per item:
  { desktop, mobile, desktopLocal, mobileLocal, publicDesktop, publicMobile }
- Filter out null/undefined/empty entries
- Handle legacy string URLs by wrapping in object with desktop property

Reference 07-RESEARCH.md Complete Migration with Dry-Run code example.
  </action>
  <verify>
Run migration in dry-run mode:
```bash
cd backend
DRY_RUN=true npx migrate-mongo up
```
Confirm:
- Shows "DRY RUN" mode indicator
- Displays sample transformations without modifying data
- Reports would-be affected product count
  </verify>
  <done>
Migration script created with dry-run support. Running `DRY_RUN=true npx migrate-mongo up` shows preview without database changes. Migration includes proper rollback in down() method.
  </done>
</task>

<task type="auto">
  <name>Task 3: Document and test rollback procedure</name>
  <files>backend/migrations/20260203000000-merge-image-arrays.js</files>
  <action>
Add documentation comments at the top of the migration file explaining:
1. Purpose of migration (unify mainImage + smallImages)
2. How to run dry-run mode
3. How to rollback with `npx migrate-mongo down`
4. What the images array structure looks like
5. Warning about keeping old fields for backwards compatibility

Then test the full cycle:
1. Run audit script to baseline
2. Run migration in dry-run mode
3. Verify dry-run output makes sense
4. Check that NO products have images field yet (dry-run didn't write)

DO NOT run actual migration yet - that's Plan 07-02.
  </action>
  <verify>
Verify dry-run leaves database unchanged:
```bash
cd backend
node -e "require('dotenv').config(); const mongoose = require('mongoose'); mongoose.connect(process.env.DB_CONNECTION_STRING).then(async () => { const count = await mongoose.connection.db.collection('products').countDocuments({images: {$exists: true}}); console.log('Products with images array:', count); mongoose.disconnect(); })"
```
Should show 0 products with images array.
  </verify>
  <done>
Migration documented with usage instructions. Dry-run verified to not modify data. Rollback procedure documented and down() method implemented.
  </done>
</task>

</tasks>

<verification>
Phase 7 Plan 01 complete when:
- [ ] Audit script exists at backend/scripts/audit-image-data.js
- [ ] Audit script runs and reports image data quality
- [ ] Migration file exists at backend/migrations/20260203000000-merge-image-arrays.js
- [ ] Migration supports DRY_RUN=true environment variable
- [ ] Dry-run shows transformation preview without modifying database
- [ ] down() method properly reverses the transformation
- [ ] Migration includes documentation comments
</verification>

<success_criteria>
- Audit script identifies all edge cases in current data
- Migration dry-run previews changes without side effects
- Rollback mechanism is implemented and documented
- All verification commands pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-image-array-migration/07-01-SUMMARY.md`
</output>
